<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FaceMesh Particle Sync Test</title>
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- TensorFlow.js and FaceMesh -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@3.11.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@3.11.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@3.11.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4.1633559619/face_mesh.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@1.0.2/dist/face-landmarks-detection.js" crossorigin="anonymous"></script>

    <!-- Three.js -->
    <script async src="https://unpkg.com/es-module-shims@1.6.3/dist/es-module-shims.js"></script>
    <script type="importmap">
    {
        "imports": {
            "three": "https://cdn.jsdelivr.net/npm/three@0.157.0/build/three.module.js",
            "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.157.0/examples/jsm/"
        }
    }
    </script>
    <link href="https://fonts.googleapis.com/css2?family=Major+Mono+Display&family=VT323&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'VT323', monospace;
            background-color: #000;
            color: #00f7ff;
            margin: 0;
            overflow: hidden;
        }
        #main-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        #info-panel {
            position: absolute;
            top: 1rem;
            left: 1rem;
            background: rgba(0,0,0,0.5);
            padding: 1rem;
            border: 1px solid #00f7ff;
            max-width: 300px;
            z-index: 10;
        }
        h1 {
            font-family: 'Major Mono Display', monospace;
            color: #00f7ff;
            text-shadow: 0 0 10px #00f7ff;
        }
        button {
            font-family: 'Major Mono Display', monospace;
            background: transparent;
            border: 2px solid #00f7ff;
            color: #00f7ff;
            padding: 0.5rem 1rem;
            cursor: pointer;
            transition: all 0.3s;
        }
        button:hover:not(:disabled) {
            background: #00f7ff;
            color: #000;
        }
        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
    </style>
</head>
<body>
    <div id="main-container">
        <canvas id="particle-canvas"></canvas>
    </div>

    <div id="info-panel" class="rounded-lg">
        <h1 class="text-2xl mb-4">PARTICLE SYNC</h1>
        <p id="status-text" class="mb-4">Awaiting initialization...</p>
        <button id="start-button">[ START SYNC ]</button>
    </div>

    <video id="video-feed" autoplay playsinline class="hidden"></video>

<script type="module">
    import * as THREE from 'three';
    import { OrbitControls } from 'three/addons/controls/OrbitControls.js';

    const statusText = document.getElementById('status-text');
    const startButton = document.getElementById('start-button');
    const video = document.getElementById('video-feed');
    const canvas = document.getElementById('particle-canvas');

    let scene, camera, renderer, controls, particleSystem, particleGeometry;
    let faceDetector;

    const NUM_KEYPOINTS = 468; // MediaPipe FaceMesh has 468 landmarks

    // --- 1. Initialization ---
    function init() {
        // Scene setup
        scene = new THREE.Scene();
        camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 15;
        
        renderer = new THREE.WebGLRenderer({ canvas: canvas, alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);

        controls = new OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;
        controls.enablePan = false;
        controls.enableZoom = true;

        // Create the initial particle system
        particleGeometry = new THREE.BufferGeometry();
        const positions = new Float32Array(NUM_KEYPOINTS * 3);
        particleGeometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
        
        const particleMaterial = new THREE.PointsMaterial({
            color: 0x00f7ff,
            size: 0.1,
            blending: THREE.AdditiveBlending,
            transparent: true,
            depthWrite: false,
        });

        particleSystem = new THREE.Points(particleGeometry, particleMaterial);
        scene.add(particleSystem);

        window.addEventListener('resize', onWindowResize, false);
        animate();
        statusText.textContent = "Ready. Press START SYNC to begin.";
    }

    function onWindowResize() {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
    }

    function animate() {
        requestAnimationFrame(animate);
        controls.update();
        renderer.render(scene, camera);
    }

    // --- 2. Face Tracking Setup ---
    async function setupFaceTracking() {
        statusText.textContent = "Requesting webcam access...";
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { width: 640, height: 480 },
                audio: false,
            });
            video.srcObject = stream;
            await new Promise((resolve) => {
                video.onloadedmetadata = resolve;
            });
        } catch (err) {
            statusText.textContent = "ERROR: Webcam access denied.";
            console.error(err);
            return;
        }

        statusText.textContent = "Loading FaceMesh model...";
        const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;
        const detectorConfig = {
            runtime: 'mediapipe',
            solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4.1633559619',
        };
        faceDetector = await faceLandmarksDetection.createDetector(model, detectorConfig);
        
        statusText.textContent = "Sync established. Tracking face...";
        detectFace();
    }

    // --- 3. Detection Loop & 3D Update ---
    async function detectFace() {
        if (!faceDetector) return;

        const faces = await faceDetector.estimateFaces(video, { flipHorizontal: false });

        if (faces.length > 0) {
            const keypoints = faces[0].keypoints;
            const positions = particleGeometry.attributes.position.array;

            for (let i = 0; i < keypoints.length; i++) {
                // Normalize and scale coordinates to fit the 3D scene
                const x = (keypoints[i].x / video.width - 0.5) * 20;
                const y = -(keypoints[i].y / video.height - 0.5) * 20;
                const z = -(keypoints[i].z / 100) * 20; // Scale and invert Z

                positions[i * 3] = x;
                positions[i * 3 + 1] = y;
                positions[i * 3 + 2] = z;
            }
            particleGeometry.attributes.position.needsUpdate = true;
        }

        requestAnimationFrame(detectFace);
    }

    // --- Event Listeners ---
    startButton.addEventListener('click', async () => {
        startButton.disabled = true;
        await setupFaceTracking();
    });

    init();
</script>
</body>
</html>
